{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import transformers\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration, T5TokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import FinQA_Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 2\n",
    "TESTING = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashish1610dhiman/opt/anaconda3/envs/dlt_project/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5.py:199: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TOKENIZER = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "MODEL = T5ForConditionalGeneration.from_pretrained(\"t5-base\", return_dict=True)\n",
    "OPTIMIZER = Adam(MODEL.parameters(), lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data and create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "finqa_train = torch.load('../finqa_dataset/finqa_train.pth')\n",
    "finqa_valid = torch.load('../finqa_dataset/finqa_valid.pth')\n",
    "# torch.save(finqa_test, '../finqa_dataset/finqa_test.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    train_loader = DataLoader(Subset(finqa_train, range(100)), batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(Subset(finqa_valid, range(10)), batch_size=BATCH_SIZE)\n",
    "else:\n",
    "    train_loader = DataLoader(finqa_train, batch_size=BATCH_SIZE)\n",
    "    val_loader = DataLoader(finqa_valid, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:   0%|          | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:   8%|▊         | 2/25 [01:16<14:42, 38.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3/25 -> Train loss: 6.2316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  16%|█▌        | 4/25 [02:33<13:25, 38.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 5/25 -> Train loss: 4.2467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  24%|██▍       | 6/25 [03:51<12:18, 38.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 7/25 -> Train loss: 3.2732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  28%|██▊       | 7/25 [04:32<11:54, 39.68s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Training batches:  32%|███▏      | 8/25 [05:14<11:22, 40.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 9/25 -> Train loss: 2.8531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  40%|████      | 10/25 [06:37<10:18, 41.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 11/25 -> Train loss: 2.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  48%|████▊     | 12/25 [08:06<09:17, 42.89s/it]Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 13/25 -> Train loss: 2.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  56%|█████▌    | 14/25 [09:35<08:03, 43.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 15/25 -> Train loss: 2.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  64%|██████▍   | 16/25 [11:16<07:10, 47.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 17/25 -> Train loss: 2.0881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  72%|███████▏  | 18/25 [13:02<05:51, 50.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 19/25 -> Train loss: 1.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  80%|████████  | 20/25 [14:36<04:02, 48.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 21/25 -> Train loss: 1.8866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  88%|████████▊ | 22/25 [16:03<02:19, 46.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 23/25 -> Train loss: 1.7716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  96%|█████████▌| 24/25 [17:46<00:48, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 25/25 -> Train loss: 1.6757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches: 100%|██████████| 25/25 [18:35<00:00, 44.63s/it]\n",
      "Validation batches: 100%|██████████| 3/3 [00:22<00:00,  7.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 -> Train loss: 1.6383\tValidation loss: 0.4996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:   8%|▊         | 2/25 [01:31<17:29, 45.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 3/25 -> Train loss: 21.3276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training batches:  12%|█▏        | 3/25 [02:20<17:12, 46.95s/it]"
     ]
    }
   ],
   "source": [
    "train_loss = 0\n",
    "val_loss = 0\n",
    "b=0\n",
    "train_hist=[]\n",
    "val_hist = []\n",
    "num_batches = len(train_loader)\n",
    "print_every=num_batches//10\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    MODEL.train()\n",
    "    for batch in tqdm(train_loader, desc=\"Training batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "        outputs = MODEL(input_ids=input_ids,attention_mask=attention_mask,\n",
    "                          labels=labels,decoder_attention_mask=decoder_attention_mask)\n",
    "        OPTIMIZER.zero_grad()\n",
    "        outputs.loss.backward()\n",
    "        OPTIMIZER.step()\n",
    "        train_loss += outputs.loss.item()\n",
    "        b+=1\n",
    "        if b%(print_every)==0:\n",
    "            print(f\"Batch {b+1}/{num_batches} -> Train loss: {train_loss/b:.4f}\")\n",
    "    train_hist.append(train_loss / len(train_loader))\n",
    "    #Evaluation\n",
    "    MODEL.eval()\n",
    "    for batch in tqdm(val_loader, desc=\"Validation batches\"):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            outputs = MODEL(input_ids=input_ids, attention_mask=attention_mask,\n",
    "                          labels=labels, decoder_attention_mask=decoder_attention_mask)\n",
    "        val_loss += outputs.loss.item()\n",
    "    val_hist.append(val_loss / len(val_loader))\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} -> Train loss: {train_hist[-1]:.4f}\\tValidation loss: {val_hist[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2,)\n",
    "axes[0].plot(train_hist)\n",
    "axes[0].set_title('Training Loss')\n",
    "\n",
    "axes[1].plot(val_hist)\n",
    "axes[1].set_title('Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL.save_pretrained(\"./finqa_finetune_t5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
